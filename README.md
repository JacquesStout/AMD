# AMD
Main folder for AMD project 2023

Diffusion preprocessing and organizing data for SAMBA:

SAMBA_prep_AMD.py
Goes through the relevant files from the AMD project, runs basic diffusion preprocesses and places all files in a specific folder in the format required for the running of SAMBA on the entire project line.

At this point, one should run SAMBA
(For details concerning SAMBA, see https://link.springer.com/article/10.1007/s12021-018-9410-0 )

SAMBA_to_DTC_AMD.py
This file goes throught he SAMBA output and will reorganize the resulting niftis, transform mats and labels so they can be easily used by the rest of the pipelien.
(ensure that the output of this file coincides with the main input folder for the rest of it) 

Generating TRK files:

mrtrix_trk_maker.py
Once SAMBA is finished, this is the file runs the mrtrix tck generation using mrtrix based on the files created as SAMBA output.
AMD_mrtrixtrk_clusterwrapper.py
this file is the main wrapper for tck generation. It parallellizes the submission of mrtrix_trk_maker on a per subject basis.

tck2trk.py
Uses mrtrix to convert tck files to trk
AMD_wrapper_tck2trk.py
Main wrapper for converting all tck files to trk

Statistical analysis:
 
AMD_subj_to_MDT_clustered.py
Will go through the trk file for the specified subject and place them in the template space generated by SAMBA (MDT)
AMD_subj_to_MDT_clusterwrapper.py
Clusters on a per subject basis the trk_MDT generation seen above

streamline_average_prep_AMD_clustered.py
This file iterates through all MDT trk files previously generated and creates the grouping and connectome files.
streamline_average_prep_clusterwrapper.py
Wrapper for the connectome+grouping generation

streamline_average_AMD.py
Using the grouping files established previously, streamline average combines the tracts of all subjects on a per Connection basis, as well as write multiple trackers for the correspondence of streamline fa information and other statistics

streamline_bundle_stats_AMD.py
Uses the sum of trk results of streamline_average_AMD and splits them into different bundles, then generates the statistical files used for analysis

streamline_bundle_view_AMD.py
Allows for the viewing of specific bundles, streamlines, etc based on the results of streamline_bundle_stats_AMD.py (good for figure generation and quality control)


Other useful files:

submit_sge_cluster_job.bash will be the main file used for submission of jobs to a computing cluster referred to in the myriad cluster wrappers.
If a cluster is not available, feel free to create a loop submitting the jobs to the 'clustered' files on a per subject basis

This pipeline will occasionally refer to the DTC pipeline, which can be found here:
https://github.com/JacquesStout/DTC
Please refer to this paper if you are to use the tools available here




